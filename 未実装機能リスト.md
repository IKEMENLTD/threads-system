# 📋 Threads自動投稿システム - 実装状況と残タスク

**最終更新**: 2025年1月15日

## ✅ 実装完了した機能

### 1. フロントエンド (100% 完了)
- ✅ HTML/CSS/JavaScript UI
- ✅ レスポンシブデザイン
- ✅ 投稿管理画面
- ✅ ダッシュボード
- ✅ モーダルダイアログ
- ✅ フィルター機能

### 2. バックエンドAPI (100% 完了)
- ✅ Express.jsサーバー
- ✅ RESTful API設計
- ✅ CORS設定
- ✅ エラーハンドリング
- ✅ Render.comデプロイ対応

### 3. データベース (90% 完了)
- ✅ PostgreSQL完全スキーマ設計
- ✅ 8テーブル実装 (users, posts, hashtags, media, analytics等)
- ✅ データベース接続モジュール (`backend/database.js`)
- ✅ トランザクション処理
- ✅ インデックス最適化
- ✅ ビュー定義
- ⚠️ Supabase本番接続（環境変数設定のみ必要）

### 4. 認証システム (80% 完了)
- ✅ bcryptパスワードハッシュ化
- ✅ ユーザー登録・ログイン
- ✅ 最終ログイン時刻記録
- ⚠️ JWT完全実装（簡易版実装済み）
- ❌ リフレッシュトークン
- ❌ メール認証

## ❌ 未実装の重要機能

## 1. 🐍 Python/Threads API連携（最優先）

### 必要なPythonファイル
```python
# threads_api.py - 要作成
import requests
from typing import Optional, Dict, List
import os
from datetime import datetime

class ThreadsAPI:
    """Threads公式API wrapper"""
    
    def __init__(self, access_token: str):
        self.access_token = access_token
        self.base_url = "https://graph.threads.net/v1.0"
        
    def create_media_container(self, 
                             content: str, 
                             media_type: str = "TEXT",
                             image_url: Optional[str] = None) -> Dict:
        """メディアコンテナ作成"""
        endpoint = f"{self.base_url}/me/threads"
        params = {
            "media_type": media_type,
            "text": content,
            "access_token": self.access_token
        }
        if image_url:
            params["image_url"] = image_url
            
        response = requests.post(endpoint, params=params)
        return response.json()
    
    def publish_media(self, container_id: str) -> Dict:
        """投稿を公開"""
        endpoint = f"{self.base_url}/me/threads_publish"
        params = {
            "creation_id": container_id,
            "access_token": self.access_token
        }
        response = requests.post(endpoint, params=params)
        return response.json()
    
    def get_insights(self, thread_id: str) -> Dict:
        """投稿の分析データ取得"""
        endpoint = f"{self.base_url}/{thread_id}/insights"
        params = {
            "metric": "views,likes,replies,reposts,quotes",
            "access_token": self.access_token
        }
        response = requests.get(endpoint, params=params)
        return response.json()
```

### 必要なSQL（Threads連携用）
```sql
-- Threads認証トークン管理
CREATE TABLE IF NOT EXISTS threads_auth (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    access_token TEXT NOT NULL,
    refresh_token TEXT,
    token_type VARCHAR(50) DEFAULT 'Bearer',
    expires_at TIMESTAMP WITH TIME ZONE,
    scope TEXT,
    threads_user_id VARCHAR(100),
    instagram_business_account VARCHAR(100),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user_id)
);

-- 投稿キュー（失敗時のリトライ用）
CREATE TABLE IF NOT EXISTS post_queue (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    post_id UUID NOT NULL REFERENCES posts(id) ON DELETE CASCADE,
    priority INTEGER DEFAULT 0,
    status VARCHAR(20) DEFAULT 'pending' CHECK (status IN ('pending', 'processing', 'completed', 'failed')),
    attempts INTEGER DEFAULT 0,
    max_attempts INTEGER DEFAULT 3,
    next_retry_at TIMESTAMP WITH TIME ZONE,
    error_log JSONB DEFAULT '[]',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    processed_at TIMESTAMP WITH TIME ZONE
);

-- API呼び出しログ
CREATE TABLE IF NOT EXISTS api_logs (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID REFERENCES users(id) ON DELETE SET NULL,
    endpoint VARCHAR(255) NOT NULL,
    method VARCHAR(10) NOT NULL,
    request_body JSONB,
    response_body JSONB,
    status_code INTEGER,
    duration_ms INTEGER,
    error_message TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- インデックス追加
CREATE INDEX idx_threads_auth_user_id ON threads_auth(user_id);
CREATE INDEX idx_threads_auth_expires_at ON threads_auth(expires_at);
CREATE INDEX idx_post_queue_status ON post_queue(status);
CREATE INDEX idx_post_queue_next_retry ON post_queue(next_retry_at);
CREATE INDEX idx_api_logs_created_at ON api_logs(created_at);
```

## 2. ⏰ 自動投稿スケジューラー

### 必要なPythonファイル
```python
# scheduler.py - 要作成
import asyncio
import psycopg2
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from datetime import datetime, timedelta
import logging

class PostScheduler:
    """投稿スケジューラー"""
    
    def __init__(self, db_url: str, threads_api):
        self.db_url = db_url
        self.threads_api = threads_api
        self.scheduler = AsyncIOScheduler()
        
    async def check_scheduled_posts(self):
        """予約投稿をチェックして実行"""
        conn = psycopg2.connect(self.db_url)
        cur = conn.cursor()
        
        # 実行時刻が来た投稿を取得
        cur.execute("""
            SELECT p.*, t.access_token 
            FROM posts p
            JOIN threads_auth t ON p.user_id = t.user_id
            WHERE p.status = 'scheduled' 
              AND p.scheduled_at <= NOW()
              AND p.deleted_at IS NULL
            ORDER BY p.scheduled_at ASC
            LIMIT 10
        """)
        
        posts = cur.fetchall()
        
        for post in posts:
            await self.publish_post(post)
            
    async def publish_post(self, post_data):
        """投稿を公開"""
        try:
            # Threads APIで投稿
            container = self.threads_api.create_media_container(
                content=post_data['content']
            )
            result = self.threads_api.publish_media(container['id'])
            
            # ステータスを更新
            self.update_post_status(
                post_data['id'], 
                'published',
                threads_post_id=result['id']
            )
            
        except Exception as e:
            logging.error(f"投稿失敗: {e}")
            self.update_post_status(
                post_data['id'], 
                'failed',
                error_message=str(e)
            )
```

### 必要なSQL（スケジューラー用）
```sql
-- スケジューラージョブ管理
CREATE TABLE IF NOT EXISTS scheduler_jobs (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    job_name VARCHAR(100) UNIQUE NOT NULL,
    job_type VARCHAR(50) NOT NULL,
    cron_expression VARCHAR(100),
    next_run_at TIMESTAMP WITH TIME ZONE,
    last_run_at TIMESTAMP WITH TIME ZONE,
    last_status VARCHAR(20),
    last_error TEXT,
    is_active BOOLEAN DEFAULT true,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- 最適投稿時間分析
CREATE TABLE IF NOT EXISTS optimal_posting_times (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    day_of_week INTEGER CHECK (day_of_week BETWEEN 0 AND 6),
    hour INTEGER CHECK (hour BETWEEN 0 AND 23),
    average_engagement_rate DECIMAL(5,2),
    sample_size INTEGER,
    calculated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user_id, day_of_week, hour)
);

-- ビュー：次の予約投稿
CREATE OR REPLACE VIEW upcoming_scheduled_posts AS
SELECT 
    p.*,
    u.username,
    u.email,
    t.access_token IS NOT NULL as has_threads_auth
FROM posts p
JOIN users u ON p.user_id = u.id
LEFT JOIN threads_auth t ON p.user_id = t.user_id
WHERE p.status = 'scheduled'
  AND p.scheduled_at > NOW()
  AND p.deleted_at IS NULL
ORDER BY p.scheduled_at ASC;
```

## 3. 📤 メディアアップロード

### 必要な実装
```javascript
// backend/media-handler.js - 要作成
const multer = require('multer');
const sharp = require('sharp');
const AWS = require('aws-sdk');

const s3 = new AWS.S3({
    accessKeyId: process.env.AWS_ACCESS_KEY_ID,
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
    region: process.env.AWS_REGION
});

const uploadToS3 = async (file) => {
    const params = {
        Bucket: process.env.AWS_S3_BUCKET,
        Key: `threads/${Date.now()}-${file.originalname}`,
        Body: file.buffer,
        ContentType: file.mimetype,
        ACL: 'public-read'
    };
    
    return await s3.upload(params).promise();
};
```

### 必要なSQL（メディア用）
```sql
-- メディア処理キュー
CREATE TABLE IF NOT EXISTS media_processing_queue (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    media_id UUID NOT NULL REFERENCES media(id) ON DELETE CASCADE,
    operation VARCHAR(50) NOT NULL, -- resize, optimize, thumbnail
    status VARCHAR(20) DEFAULT 'pending',
    input_path TEXT NOT NULL,
    output_path TEXT,
    options JSONB DEFAULT '{}',
    error_message TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP WITH TIME ZONE
);

-- CDN配信URL管理
CREATE TABLE IF NOT EXISTS media_cdn_urls (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    media_id UUID NOT NULL REFERENCES media(id) ON DELETE CASCADE,
    cdn_provider VARCHAR(50) NOT NULL, -- cloudfront, cloudflare
    url TEXT NOT NULL,
    region VARCHAR(20),
    expires_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

## 4. 📊 高度な分析機能

### 必要なSQL（分析用）
```sql
-- エンゲージメント予測モデル
CREATE TABLE IF NOT EXISTS engagement_predictions (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    post_id UUID REFERENCES posts(id) ON DELETE CASCADE,
    predicted_likes INTEGER,
    predicted_comments INTEGER,
    predicted_shares INTEGER,
    predicted_engagement_rate DECIMAL(5,2),
    confidence_score DECIMAL(3,2),
    model_version VARCHAR(20),
    features_used JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- A/Bテスト結果
CREATE TABLE IF NOT EXISTS ab_test_results (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    test_name VARCHAR(100) NOT NULL,
    variant_a_post_id UUID REFERENCES posts(id),
    variant_b_post_id UUID REFERENCES posts(id),
    metric_name VARCHAR(50), -- likes, comments, engagement_rate
    variant_a_value DECIMAL(10,2),
    variant_b_value DECIMAL(10,2),
    statistical_significance DECIMAL(3,2),
    winner VARCHAR(1),
    test_duration_hours INTEGER,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- ハッシュタグパフォーマンス
CREATE TABLE IF NOT EXISTS hashtag_performance (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    hashtag_id UUID NOT NULL REFERENCES hashtags(id) ON DELETE CASCADE,
    period_start DATE NOT NULL,
    period_end DATE NOT NULL,
    total_posts INTEGER DEFAULT 0,
    avg_likes DECIMAL(10,2),
    avg_comments DECIMAL(10,2),
    avg_engagement_rate DECIMAL(5,2),
    trending_score DECIMAL(5,2),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(hashtag_id, period_start, period_end)
);

-- 集計ビュー：週次パフォーマンス
CREATE OR REPLACE VIEW weekly_performance AS
SELECT 
    u.username,
    DATE_TRUNC('week', p.published_at) as week,
    COUNT(p.id) as total_posts,
    AVG(a.likes_count) as avg_likes,
    AVG(a.comments_count) as avg_comments,
    AVG(a.engagement_rate) as avg_engagement_rate,
    SUM(a.reach_count) as total_reach
FROM posts p
JOIN users u ON p.user_id = u.id
LEFT JOIN analytics a ON p.id = a.post_id
WHERE p.status = 'published'
  AND p.published_at IS NOT NULL
GROUP BY u.username, DATE_TRUNC('week', p.published_at)
ORDER BY week DESC, u.username;
```

## 5. 🔔 通知システム

### 必要なSQL（通知用）
```sql
-- 通知設定
CREATE TABLE IF NOT EXISTS notification_settings (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    channel VARCHAR(20) NOT NULL CHECK (channel IN ('email', 'slack', 'webhook', 'push')),
    event_type VARCHAR(50) NOT NULL, -- post_published, post_failed, engagement_milestone
    is_enabled BOOLEAN DEFAULT true,
    config JSONB DEFAULT '{}', -- channel固有の設定
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user_id, channel, event_type)
);

-- 通知履歴
CREATE TABLE IF NOT EXISTS notification_history (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    channel VARCHAR(20) NOT NULL,
    event_type VARCHAR(50) NOT NULL,
    title VARCHAR(200),
    message TEXT,
    metadata JSONB DEFAULT '{}',
    status VARCHAR(20) DEFAULT 'sent',
    error_message TEXT,
    sent_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

## 🚀 実装優先順位（更新版）

### Phase 1: Threads API基本連携（1週間）
1. ✅ データベース接続（完了）
2. ⏳ Threads OAuth認証実装
3. ⏳ 基本投稿機能
4. ⏳ エラーハンドリング

### Phase 2: 自動化機能（1週間）
1. ⏳ スケジューラー実装
2. ⏳ リトライ機能
3. ⏳ 投稿キュー管理
4. ⏳ 通知システム基本版

### Phase 3: メディア対応（3日）
1. ⏳ 画像アップロード
2. ⏳ S3/Cloudinary連携
3. ⏳ 画像最適化
4. ⏳ サムネイル生成

### Phase 4: 分析機能（1週間）
1. ⏳ 分析データ自動収集
2. ⏳ レポート生成
3. ⏳ 最適投稿時間分析
4. ⏳ ハッシュタグ効果測定

## 📦 必要なパッケージ（更新版）

### Backend (package.json)
```json
{
  "dependencies": {
    "express": "^4.18.2",         // ✅ インストール済み
    "cors": "^2.8.5",             // ✅ インストール済み
    "dotenv": "^16.3.1",          // ✅ インストール済み
    "pg": "^8.11.3",              // ✅ インストール済み
    "bcryptjs": "^2.4.3",         // ✅ インストール済み
    "jsonwebtoken": "^9.0.2",     // ⏳ 要インストール
    "multer": "^1.4.5-lts.1",     // ⏳ 要インストール
    "sharp": "^0.33.0",           // ⏳ 要インストール
    "aws-sdk": "^2.1500.0",       // ⏳ 要インストール
    "node-cron": "^3.0.3",        // ⏳ 要インストール
    "nodemailer": "^6.9.7",       // ⏳ 要インストール
    "bull": "^4.11.5",            // ⏳ 要インストール（ジョブキュー）
    "redis": "^4.6.10"            // ⏳ 要インストール
  }
}
```

### Python (requirements.txt)
```txt
# Threads API
requests==2.31.0          # ⏳ 要インストール
python-dotenv==1.0.0      # ⏳ 要インストール

# データベース
psycopg2-binary==2.9.9    # ⏳ 要インストール

# スケジューラー
APScheduler==3.10.4       # ⏳ 要インストール
asyncio==3.4.3           # ⏳ 要インストール

# Web framework
fastapi==0.104.1         # ⏳ 要インストール
uvicorn==0.24.0          # ⏳ 要インストール

# 分析
pandas==2.1.3            # ⏳ 要インストール
numpy==1.26.2            # ⏳ 要インストール
```

## 📈 実装進捗サマリー

| カテゴリ | 完了率 | 残作業 |
|---------|--------|--------|
| フロントエンド | 100% | なし |
| バックエンドAPI | 100% | なし |
| データベース | 90% | Supabase接続設定のみ |
| 認証システム | 80% | JWT完全実装、メール認証 |
| Threads API | 0% | 全て未実装 |
| 自動投稿 | 0% | 全て未実装 |
| メディア処理 | 0% | 全て未実装 |
| 分析機能 | 10% | 基本テーブルのみ実装 |
| 通知システム | 0% | 全て未実装 |

## 🎯 次のアクション

1. **最優先**: Threads OAuth認証の実装
2. **優先**: Python環境構築とThreads API wrapper作成
3. **重要**: スケジューラー実装で自動投稿を実現
4. **推奨**: メディアアップロード機能の追加

**推定完了時間**: 3-4週間（フルタイム開発の場合）